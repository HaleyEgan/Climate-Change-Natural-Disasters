{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMoEiJ1paqHp6tMwMslNL2K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dmd8a/Climate-Change-Natural-Disasters/blob/main/Homework4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrN0p6WV6czR",
        "outputId": "2de39b8d-5505-4317-a4a9-c18e30f2683a"
      },
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "filename = 'netflix_titles.csv'\n",
        "df = pd.read_csv('/content/drive/MyDrive/netflix_titles.csv')\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XurxdtjW8WKh"
      },
      "source": [
        "**Question 1**. First, try to find all duplicate entries.  I began by searching for duplicate titles, and found none.  There are multiple entries with duplicate directors, as expected, but none with the same title (hence of course none with the same full row)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxdv9BNR6nbW",
        "outputId": "a6731269-1f84-475f-aace-d162770e296b"
      },
      "source": [
        "print(df.shape) # 7787 rows and 12 columns\n",
        "\n",
        "# how many entries have the same title?  apparently none\n",
        "\n",
        "duplicateTitles = df[df.duplicated(['title'])]\n",
        "print(duplicateTitles)\n",
        "\n",
        "# proof of concept: how many entries have the same director?  many\n",
        "\n",
        "duplicateDirectors = df[df.duplicated(['director'])]\n",
        "print(duplicateDirectors)\n",
        "print(duplicateDirectors.count(axis=0)) "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7787, 12)\n",
            "Empty DataFrame\n",
            "Columns: [show_id, type, title, director, cast, country, date_added, release_year, rating, duration, listed_in, description]\n",
            "Index: []\n",
            "     show_id  ...                                        description\n",
            "11       s12  ...  In this dark alt-history thriller, a na√Øve law...\n",
            "16       s17  ...  As a psychology professor faces Alzheimer's, h...\n",
            "19       s20  ...  Mixing old footage with interviews, this is th...\n",
            "24       s25  ...  Seiya and the Knights of the Zodiac rise again...\n",
            "26       s27  ...  This docuseries takes a deep dive into the luc...\n",
            "...      ...  ...                                                ...\n",
            "7778   s7779  ...  Looking to survive in a world taken over by zo...\n",
            "7779   s7780  ...  An assortment of talent takes the stage for a ...\n",
            "7780   s7781  ...  A drug dealer starts having doubts about his t...\n",
            "7784   s7785  ...  In this documentary, South African rapper Nast...\n",
            "7785   s7786  ...  Dessert wizard Adriano Zumbo looks for the nex...\n",
            "\n",
            "[3737 rows x 12 columns]\n",
            "show_id         3737\n",
            "type            3737\n",
            "title           3737\n",
            "director        1349\n",
            "cast            3379\n",
            "country         3370\n",
            "date_added      3727\n",
            "release_year    3737\n",
            "rating          3732\n",
            "duration        3737\n",
            "listed_in       3737\n",
            "description     3737\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eujEEgbD8jxD"
      },
      "source": [
        "Next, I made all titles lower-case to find any hidden duplicates.  Still none."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRk-8UdN61qj",
        "outputId": "c2c7b248-4e1f-46b4-eed7-72d4bc125124"
      },
      "source": [
        "# make the title all lower-case to see if we're missing any duplicates\n",
        "\n",
        "lowercaseTitle = df['title'].str.lower()\n",
        "print(lowercaseTitle.tail()) # to be sure the code is what it should be\n",
        "#duplicateTitleslc = lowercaseTitle[lowercaseTitle.duplicated()]\n",
        "#print(duplicateTitleslc)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7782                                       zozo\n",
            "7783                                     zubaan\n",
            "7784                          zulu man in japan\n",
            "7785                      zumbo's just desserts\n",
            "7786    zz top: that little ol' band from texas\n",
            "Name: title, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQ3lF_gG8rBL"
      },
      "source": [
        "**Question 2**.  Find the percentage of missing data in each column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPGLB_qT-FJr",
        "outputId": "a10d4dd7-b69b-4429-f0ef-cde6af2daa57"
      },
      "source": [
        "counts=df.count() # gives the number of non-missing entries in each column\n",
        "proportion_missing = 1 - (counts / len(df))\n",
        "percent_missing = proportion_missing*100\n",
        "print(percent_missing)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "show_id          0.000000\n",
            "type             0.000000\n",
            "title            0.000000\n",
            "director        30.679337\n",
            "cast             9.220496\n",
            "country          6.510851\n",
            "date_added       0.128419\n",
            "release_year     0.000000\n",
            "rating           0.089893\n",
            "duration         0.000000\n",
            "listed_in        0.000000\n",
            "description      0.000000\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BU6FF60qDYwV"
      },
      "source": [
        "This is another way to compute the percentage of missing data.  I'm including it here for my own reference."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAxaqM2eDV-e",
        "outputId": "b917b4cc-3197-4366-a30f-0009365733b4"
      },
      "source": [
        "df_missing = df.isna()\n",
        "df_prop_missing=df_missing.mean()\n",
        "percent_missing=df_prop_missing*100\n",
        "print(percent_missing)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "show_id          0.000000\n",
            "type             0.000000\n",
            "title            0.000000\n",
            "director        30.679337\n",
            "cast             9.220496\n",
            "country          6.510851\n",
            "date_added       0.128419\n",
            "release_year     0.000000\n",
            "rating           0.089893\n",
            "duration         0.000000\n",
            "listed_in        0.000000\n",
            "description      0.000000\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwS1veIaE5Lo"
      },
      "source": [
        "**Question 3**.  Extract date information, adding three columns to the data frame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53kffvZeE4lT",
        "outputId": "b6c8b735-b149-4685-ae17-f07924b2ba91"
      },
      "source": [
        " #print(df['date_added']) #first, figure out how the dates are entered - looks \n",
        " # like day space month comma space year\n",
        "\n",
        "date_split1=df['date_added'].str.split(',', expand=True) #splits off the month / day\n",
        "# from the year, where year is in column=1\n",
        "#print(date_split1.head())\n",
        "\n",
        "date_split2=date_split1[0].str.split(' ',expand=True) # splits the month from the day,\n",
        "# where month is in column 0 and day is in column 1\n",
        "\n",
        "month = date_split2[0] #creates a data frame just with the month\n",
        "day = date_split2[1] # creates a data frame just with the day\n",
        "year = date_split1[1] # creates a data frame just with the year\n",
        "df2 = pd.concat([df,year,month], axis=1) # add the year and month to the data frame\n",
        "df2.rename(columns = {0: 'date_added_month', 1: 'date_added_year'}, inplace = True) # renamed the year and month columns\n",
        "#print(df2.head())\n",
        "\n",
        "df3 = pd.concat([df2,day], axis=1) # add the day column\n",
        "df3.rename(columns = {1: 'date_added_day'}, inplace = True) \n",
        "print(df3.head())\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  show_id     type  title  ... date_added_year date_added_month date_added_day\n",
            "0      s1  TV Show     3%  ...            2020           August             14\n",
            "1      s2    Movie   7:19  ...            2016         December             23\n",
            "2      s3    Movie  23:59  ...            2018         December             20\n",
            "3      s4    Movie      9  ...            2017         November             16\n",
            "4      s5    Movie     21  ...            2020          January              1\n",
            "\n",
            "[5 rows x 15 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zPAk92YKBkN"
      },
      "source": [
        "**Question 4**. Separate the duration column into minutes or Seasons."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2psu62HKSjB",
        "outputId": "7ecbca7d-2b96-4838-98bd-4a31dcea20c7"
      },
      "source": [
        "seasondf = df3['duration'].loc[df3['duration'].str.contains('Season', case=False)]\n",
        "# creates a data frame of entries from the duration column that had seasons\n",
        "#print(seasondf.head())\n",
        "\n",
        "minutesdf = df3['duration'].loc[df3['duration'].str.contains('min', case=False)] \n",
        "# creates a data frame of entries from the duration column that had minutes\n",
        "#print(minutesdf.head())\n",
        "\n",
        "newdf3=df3.drop(['duration'], axis=1) # drops the original 'duration' column\n",
        "\n",
        "df4 = pd.concat([newdf3, seasondf], axis=1) # tacks on a season column, if the duration\n",
        "# column had seasons\n",
        "df4.rename(columns = {'duration': 'seasons'}, inplace = True) # renames the added column\n",
        "#print(df4.head())\n",
        "\n",
        "df5 = pd.concat([df4, minutesdf], axis=1)\n",
        "df5.rename(columns = {'duration': 'minutes'}, inplace = True) # renames the minutes column\n",
        "print(df5.head()) # this is the final answer\n",
        "\n",
        "print(df5.columns) # just checking that we have all the columns\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  show_id     type  title  ... date_added_day    seasons  minutes\n",
            "0      s1  TV Show     3%  ...             14  4 Seasons      NaN\n",
            "1      s2    Movie   7:19  ...             23        NaN   93 min\n",
            "2      s3    Movie  23:59  ...             20        NaN   78 min\n",
            "3      s4    Movie      9  ...             16        NaN   80 min\n",
            "4      s5    Movie     21  ...              1        NaN  123 min\n",
            "\n",
            "[5 rows x 16 columns]\n",
            "Index(['show_id', 'type', 'title', 'director', 'cast', 'country', 'date_added',\n",
            "       'release_year', 'rating', 'listed_in', 'description', 'date_added_year',\n",
            "       'date_added_month', 'date_added_day', 'seasons', 'minutes'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    }
  ]
}